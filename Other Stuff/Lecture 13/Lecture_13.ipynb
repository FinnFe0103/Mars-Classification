{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# <center> Lecture--13 \"Data Mining, Machine Learning and Deep Learning\"\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Q1: Apply CNN for MNIST\n",
    "- Build your own CNN from scratch and try to achieve the highest possible accuracy on MNIST. The model should use 2 convolutional layers, followed by 1 pooling layer, then dropout 25%, then a dense layer, another dropout layer but with 50% dropout, and finally the output layer. It should reache more than 90% accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given: Load the data and seperate\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "X_train_full = X_train_full / 255.\n",
    "X_test = X_test / 255.\n",
    "X_train, X_valid = X_train_full[:-5000], X_train_full[-5000:]\n",
    "y_train, y_valid = y_train_full[:-5000], y_train_full[-5000:]\n",
    "\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_valid = X_valid[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO] Build your CNN based on the above instruction\n",
    "# [Hints] Before Dropout apply ReLU and after apply softmax\n",
    "# [Hins] You should also use sparse categorical cross-entropy as loss function and \"nadam\" optimizer=\"nadam\" with 10 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KwQtSOz0VrVX"
   },
   "source": [
    "## Exercise Q1: Image Classification Using convolution kernel: classify cats or dogs from images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gN7G9GFmVrVY"
   },
   "source": [
    "- Build the model\n",
    "    - Model consists of three convolution blocks with a max pool layer in each of them. There's a fully connected layer with 512 units on top of it that is activated by a `relu` activation function.\n",
    "    - Choose the ADAM optimizer and binary cross entropy loss function.\n",
    "- Train the model\n",
    "    - Parameters for pre-processing the dataset and training the network: batch_size = 128, epochs = 15, image height = 150, image width = 150 \n",
    "\n",
    "- [Hints] \n",
    "    - Builds an image classifier using a `tf.keras.Sequential` model and load data using `tf.keras.preprocessing.image.ImageDataGenerator`. \n",
    "    - Building _data input pipelines_ using the `tf.keras.preprocessing.image.ImageDataGenerator` class to efficiently work with data to use with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1WtoaOHVrVh"
   },
   "outputs": [],
   "source": [
    "## Import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C1nqr-CYY6uw"
   },
   "outputs": [],
   "source": [
    "# Load data: from <a href=\"https://www.kaggle.com/c/dogs-vs-cats/data\" target=\"_blank\">Dogs vs Cats</a> dataset from Kaggle. \n",
    "# Download the archive version of the dataset and store it in the \"/tmp/\" directory.\n",
    "\n",
    "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "\n",
    "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
    "\n",
    "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sRucI3QqVrVy"
   },
   "outputs": [],
   "source": [
    "# [TODO] After extracting its contents, assign variables with the proper file path for the training and validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vc4u8e9hVrV4"
   },
   "outputs": [],
   "source": [
    "# [TODO] understand the data: look at how many cats and dogs images are in the training and validation directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3NqNselLVrWA"
   },
   "outputs": [],
   "source": [
    "# [TODO], set up variables to use while pre-processing the dataset and training the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "syDdF_LWVrWE"
   },
   "outputs": [],
   "source": [
    "# Data preparation: Format the images into appropriately pre-processed floating point tensors before feeding to the network:\n",
    "\n",
    "# 1. Read images from the disk.\n",
    "# 2. Decode contents of these images and convert it into proper grid format as per their RGB content.\n",
    "# 3. Convert them into floating point tensors.\n",
    "# 4. Rescale the tensors from values between 0 and 255 to values between 0 and 1, as neural networks prefer to deal with small input values.\n",
    "# Use `ImageDataGenerator` class provided by `tf.keras` for all 4 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pw94ajOOVrWI"
   },
   "outputs": [],
   "source": [
    "# [TODO] After defining the generators for training and validation images, the `flow_from_directory` method load images \n",
    "# from the disk, applies rescaling, and resizes the images into the required dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3f0Z7NZgVrWQ"
   },
   "outputs": [],
   "source": [
    "# [TODO] Visualize the training images by extracting a batch of images from the training \n",
    "# generator—which is 32 images in this example—then plot five of them with `matplotlib`.\n",
    "\n",
    "# [Hints] The `next` function returns a batch from the dataset. \n",
    "# The return value of `next` function is in form of `(x_train, y_train)` \n",
    "# Discard the labels to only visualize the training images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMt2RES_VrWU"
   },
   "outputs": [],
   "source": [
    "# [TODO] Plot images in the form of a grid with 1 row and 5 columns where images are placed in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F15-uwLPVrWa"
   },
   "outputs": [],
   "source": [
    "# [TODO] Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Mg7_TXOVrWd"
   },
   "outputs": [],
   "source": [
    "# [TODO] Compile the model: *ADAM* optimizer and *binary cross entropy* loss function. \n",
    "# view training and validation accuracy for each training epoch, pass the `metrics` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vtny8hmBVrWh"
   },
   "outputs": [],
   "source": [
    "# [TODO] View all the layers of the network using the model's `summary` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KSF2HqhDVrWk"
   },
   "outputs": [],
   "source": [
    "# [TODO] Use the `fit_generator` method of the `ImageDataGenerator` class to train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K6oA77ADVrWp"
   },
   "outputs": [],
   "source": [
    "# [TODO] Now visualize the results after training the network."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "classification.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
