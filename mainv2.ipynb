{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install imblearn\n",
    "#!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. READ-IN DATA TO DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10815, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESP_013049_0950_RED-0067.jpg</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ESP_019697_2020_RED-0024.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ESP_015962_1695_RED-0016.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ESP_013049_0950_RED-0118.jpg</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ESP_015962_1695_RED-0017.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image  label\n",
       "0   ESP_013049_0950_RED-0067.jpg      7\n",
       "7   ESP_019697_2020_RED-0024.jpg      1\n",
       "14  ESP_015962_1695_RED-0016.jpg      1\n",
       "21  ESP_013049_0950_RED-0118.jpg      7\n",
       "28  ESP_015962_1695_RED-0017.jpg      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"labels-map-proj_v3_2.txt\", sep=\" \", header=None, names=[\"image\", \"label\"])\n",
    "\n",
    "# filter all images that end with fv, brt, r90, r180, r270, and fh\n",
    "df = df[~df[\"image\"].str.contains(\"fv|brt|r90|r180|r270|fh\")]\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8802\n",
       "1     794\n",
       "6     298\n",
       "3     267\n",
       "4     250\n",
       "2     166\n",
       "7     164\n",
       "5      74\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DELETE 8k RANDOM IMAGES & SHUFFLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1100\n",
       "1     794\n",
       "6     298\n",
       "3     267\n",
       "4     250\n",
       "2     166\n",
       "7     164\n",
       "5      74\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delte 7802 random images from the category with label 0\n",
    "df_us = df.drop(df[df[\"label\"] == 0].sample(7702, random_state=1).index)\n",
    "df_us[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESP_018720_2655_RED-0035.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESP_046991_0950_RED-0024.jpg</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESP_039350_1915_RED-0186.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESP_014156_1865_RED-0023.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESP_013049_0950_RED-0088.jpg</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          image  label\n",
       "0  ESP_018720_2655_RED-0035.jpg      2\n",
       "1  ESP_046991_0950_RED-0024.jpg      7\n",
       "2  ESP_039350_1915_RED-0186.jpg      1\n",
       "3  ESP_014156_1865_RED-0023.jpg      3\n",
       "4  ESP_013049_0950_RED-0088.jpg      7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle the dataframe\n",
    "df_us = df_us.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "df_us.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. READ-IN TO PIXELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_labels_from_df(df, folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i in range(len(df)):\n",
    "        img = cv2.imread(folder+\"/\"+df.iloc[i][0], cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            labels.append(df.iloc[i][1])\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7] [1100  794  166  267  250   74  298  164]\n",
      "3113\n"
     ]
    }
   ],
   "source": [
    "X, y = load_images_labels_from_df(df_us, \"map-proj-v3_2\")\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(unique, counts)\n",
    "print(X.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. NORMALIZE DATA TO 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "X_norm = X / 255.0\n",
    "print(X_norm.min())\n",
    "print(X_norm.max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. TRAIN-TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2179, 227, 227) (934, 227, 227) (2179,) (934,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.3, random_state=1)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([774, 539, 115, 176, 183,  52, 222, 118]))\n",
      "[0.35520881 0.24736117 0.0527765  0.080771   0.08398348 0.02386416\n",
      " 0.1018816  0.05415328]\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([326, 255,  51,  91,  67,  22,  76,  46]))\n",
      "[0.3490364  0.27301927 0.05460385 0.09743041 0.07173448 0.0235546\n",
      " 0.08137045 0.04925054]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train, return_counts=True))\n",
    "print(np.unique(y_train, return_counts=True)[1]/y_train.shape[0])\n",
    "\n",
    "print(np.unique(y_test, return_counts=True))\n",
    "print(np.unique(y_test, return_counts=True)[1]/y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774\n",
      "539\n",
      "115\n",
      "176\n",
      "183\n",
      "52\n",
      "222\n",
      "118\n"
     ]
    }
   ],
   "source": [
    "max_images = np.unique(y_train, return_counts=True)[1].max()\n",
    "n_images = np.unique(y_train, return_counts=True)[1]\n",
    "classes = np.unique(y_train, return_counts=True)[0]\n",
    "diff = =\n",
    "\n",
    "for i in classes:\n",
    "    if n_images[i] < max_images:\n",
    "\n",
    "    \n",
    "    print(n_images[i])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. IMBALANCE HANDLING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2179, 227, 227)\n",
      "(2179, 51529)\n"
     ]
    }
   ],
   "source": [
    "X_reshaped = X_train.flatten().reshape(X_train.shape[0], 51529)\n",
    "print(X_train.shape)\n",
    "print(X_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "adasyn = ADASYN(sampling_strategy=\"not majority\", random_state=1)\n",
    "X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_reshaped, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6226, 51529)\n",
      "[0 1 2 3 4 5 6 7] [774 539 115 176 183  52 222 118]\n",
      "[0 1 2 3 4 5 6 7] [774 824 763 772 789 762 760 782]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "unique_a, counts_a = np.unique(y_train_adasyn, return_counts=True)\n",
    "print(X_train_adasyn.shape)\n",
    "print(unique, counts)\n",
    "print(unique_a, counts_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "778.25"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the array counts_a\n",
    "np.sort(counts_a)\n",
    "np.average(counts_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6226, 227, 227)\n",
      "(6226,)\n"
     ]
    }
   ],
   "source": [
    "X_t_A = X_train_adasyn.reshape(X_train_adasyn.shape[0], 227, 227)\n",
    "y_t_A = y_train_adasyn\n",
    "print(X_t_A.shape)\n",
    "print(y_t_A.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 OVERSAMPLING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. AUGMENTATION\n",
    "1. Rotate 90\n",
    "2. Rotate 180\n",
    "3. Rotate 270\n",
    "4. Flip Horizontally\n",
    "5. Flip Vertically\n",
    "6. Zoom\n",
    "7. (Random Brightness)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom_at(img, zoom=1.0):\n",
    "    h, w, = [ zoom * i for i in img.shape ]\n",
    "    cx, cy = w/2, h/2\n",
    "    img = cv2.resize( img, (0, 0), fx=zoom, fy=zoom)\n",
    "    img = img[int(round(cy - h/zoom * .5)) : int(round(cy + h/zoom * .5)),\n",
    "              int(round(cx - w/zoom * .5)) : int(round(cx + w/zoom * .5))]\n",
    "    return img\n",
    "\n",
    "# function that rotates an image by 90, 180, and 270 degrees and flips it horizontally and vertically and zooms in on the image and adjusts the brightness randomly\n",
    "def augment_image_zoom(img):\n",
    "    img_90 = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE) # rotate the image by 90 degrees clockwise\n",
    "    img_180 = cv2.rotate(img, cv2.ROTATE_180) # rotate the image by 180 degrees\n",
    "    img_270 = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE) # rotate the image by 270 degrees clockwise\n",
    "    img_fh = cv2.flip(img, 1) # flip the image horizontally\n",
    "    img_fv = cv2.flip(img, 0) # flip the image vertically\n",
    "    img_zoom = zoom_at(img, 1.2) # zoom in on the image\n",
    "    img_brt = cv2.convertScaleAbs(img, beta=0.8) # adjust the brightness randomly\n",
    "    return img, img_90, img_180, img_270, img_fh, img_fv, img_zoom, img_brt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function that creates a copy of that image and adds it to the X_t_A array\n",
    "def add_image(X_t_A, y_t_A, img, label):\n",
    "    X_t_A = np.append(X_t_A, img)\n",
    "    y_t_A = np.append(y_t_A, label)\n",
    "    return X_t_A, y_t_A"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Apply Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.1 AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(96, (11, 11), strides=(4, 4), padding='valid', activation='relu') # layer that convolves the input image with 96 different filters that are 11x11 pixels in size\n",
    "    keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid') # layer that downsamples the input representation by taking the maximum value over the window defined by pool_size for each dimension along the features axis\n",
    "    keras.layers.Conv2D(256, (5, 5), strides=(1, 1), padding='same', activation='relu') # layer that convolves the input image with 256 different filters that are 5x5 pixels in size\n",
    "    keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid') # layer that downsamples the input representation by taking the maximum value over the window defined by pool_size for each dimension along the features axis\n",
    "    keras.layers.Conv2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu') # layer that convolves the input image with 384 different filters that are 3x3 pixels in size\n",
    "    keras.layers.Conv2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu') # layer that convolves the input image with 384 different filters that are 3x3 pixels in size\n",
    "    keras.layers.Conv2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu') # layer that convolves the input image with 384 different filters that are 3x3 pixels in size\n",
    "    keras.layers.Dense(4096, activation='relu') # layer with 4096 neurons that uses the ReLU activation function and is fully connected\n",
    "    keras.layers.Dropout(0.5), # layer that randomly sets input units to 0 with a 50% frequency at each step during training time, which helps prevent overfitting\n",
    "    keras.layers.Dense(4096, activation='relu') # layer with 4096 neurons that uses the ReLU activation function and is fully connected\n",
    "    keras.layers.Dropout(0.5), # layer that randomly sets input units to 0 with a 50% frequency at each step during training time, which helps prevent overfitting\n",
    "    keras.layers.Dense(8, activation='softmax') # layer with 8 neurons that uses the softmax activation function to output probabilities for each class\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hyperparameter Optimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
