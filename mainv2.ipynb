{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install imblearn\n",
    "#!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. READ-IN DATA TO DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10815, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESP_013049_0950_RED-0067.jpg</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ESP_019697_2020_RED-0024.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ESP_015962_1695_RED-0016.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ESP_013049_0950_RED-0118.jpg</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ESP_015962_1695_RED-0017.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           image  label\n",
       "0   ESP_013049_0950_RED-0067.jpg      7\n",
       "7   ESP_019697_2020_RED-0024.jpg      1\n",
       "14  ESP_015962_1695_RED-0016.jpg      1\n",
       "21  ESP_013049_0950_RED-0118.jpg      7\n",
       "28  ESP_015962_1695_RED-0017.jpg      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"labels-map-proj_v3_2.txt\", sep=\" \", header=None, names=[\"image\", \"label\"])\n",
    "\n",
    "# filter all images that end with fv, brt, r90, r180, r270, and fh\n",
    "df = df[~df[\"image\"].str.contains(\"fv|brt|r90|r180|r270|fh\")]\n",
    "print(df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8802\n",
       "1     794\n",
       "6     298\n",
       "3     267\n",
       "4     250\n",
       "2     166\n",
       "7     164\n",
       "5      74\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DELETE 8k RANDOM IMAGES & SHUFFLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1100\n",
       "1     794\n",
       "6     298\n",
       "3     267\n",
       "4     250\n",
       "2     166\n",
       "7     164\n",
       "5      74\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# delte 7802 random images from the category with label 0\n",
    "df_us = df.drop(df[df[\"label\"] == 0].sample(7702, random_state=1).index)\n",
    "df_us[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ESP_018720_2655_RED-0035.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESP_046991_0950_RED-0024.jpg</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESP_039350_1915_RED-0186.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ESP_014156_1865_RED-0023.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ESP_013049_0950_RED-0088.jpg</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          image  label\n",
       "0  ESP_018720_2655_RED-0035.jpg      2\n",
       "1  ESP_046991_0950_RED-0024.jpg      7\n",
       "2  ESP_039350_1915_RED-0186.jpg      1\n",
       "3  ESP_014156_1865_RED-0023.jpg      3\n",
       "4  ESP_013049_0950_RED-0088.jpg      7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle the dataframe\n",
    "df_us = df_us.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "df_us.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. READ-IN TO PIXELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_labels_from_df(df, folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i in range(len(df)):\n",
    "        img = cv2.imread(folder+\"/\"+df.iloc[i][0], cv2.IMREAD_GRAYSCALE)\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "            labels.append(df.iloc[i][1])\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7] [1100  794  166  267  250   74  298  164]\n",
      "3113\n"
     ]
    }
   ],
   "source": [
    "X, y = load_images_labels_from_df(df_us, \"map-proj-v3_2\")\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(unique, counts)\n",
    "print(X.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. NORMALIZE DATA TO 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "X_norm = X / 255.0\n",
    "print(X_norm.min())\n",
    "print(X_norm.max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. TRAIN-TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2179, 227, 227) (934, 227, 227) (2179,) (934,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size=0.3, random_state=1)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([774, 539, 115, 176, 183,  52, 222, 118]))\n",
      "[0.35520881 0.24736117 0.0527765  0.080771   0.08398348 0.02386416\n",
      " 0.1018816  0.05415328]\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([326, 255,  51,  91,  67,  22,  76,  46]))\n",
      "[0.3490364  0.27301927 0.05460385 0.09743041 0.07173448 0.0235546\n",
      " 0.08137045 0.04925054]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train, return_counts=True))\n",
    "print(np.unique(y_train, return_counts=True)[1]/y_train.shape[0])\n",
    "\n",
    "print(np.unique(y_test, return_counts=True))\n",
    "print(np.unique(y_test, return_counts=True)[1]/y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774\n",
      "539\n",
      "115\n",
      "176\n",
      "183\n",
      "52\n",
      "222\n",
      "118\n"
     ]
    }
   ],
   "source": [
    "max_images = np.unique(y_train, return_counts=True)[1].max()\n",
    "n_images = np.unique(y_train, return_counts=True)[1]\n",
    "classes = np.unique(y_train, return_counts=True)[0]\n",
    "diff = =\n",
    "\n",
    "for i in classes:\n",
    "    if n_images[i] < max_images:\n",
    "\n",
    "    \n",
    "    print(n_images[i])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. IMBALANCE HANDLING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.1 ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2179, 227, 227)\n",
      "(2179, 51529)\n"
     ]
    }
   ],
   "source": [
    "X_reshaped = X_train.flatten().reshape(X_train.shape[0], 51529)\n",
    "print(X_train.shape)\n",
    "print(X_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "adasyn = ADASYN(sampling_strategy=\"not majority\", random_state=1)\n",
    "X_train_adasyn, y_train_adasyn = adasyn.fit_resample(X_reshaped, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6226, 51529)\n",
      "[0 1 2 3 4 5 6 7] [774 539 115 176 183  52 222 118]\n",
      "[0 1 2 3 4 5 6 7] [774 824 763 772 789 762 760 782]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "unique_a, counts_a = np.unique(y_train_adasyn, return_counts=True)\n",
    "print(X_train_adasyn.shape)\n",
    "print(unique, counts)\n",
    "print(unique_a, counts_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "778.25"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort the array counts_a\n",
    "np.sort(counts_a)\n",
    "np.average(counts_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6226, 227, 227)\n",
      "(6226,)\n"
     ]
    }
   ],
   "source": [
    "X_t_A = X_train_adasyn.reshape(X_train_adasyn.shape[0], 227, 227)\n",
    "y_t_A = y_train_adasyn\n",
    "print(X_t_A.shape)\n",
    "print(y_t_A.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 OVERSAMPLING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. AUGMENTATION\n",
    "1. Rotate 90\n",
    "2. Rotate 180\n",
    "3. Rotate 270\n",
    "4. Flip Horizontally\n",
    "5. Flip Vertically\n",
    "6. Zoom\n",
    "7. (Random Brightness)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zoom_at(img, zoom=1.0):\n",
    "    h, w, = [ zoom * i for i in img.shape ]\n",
    "    cx, cy = w/2, h/2\n",
    "    img = cv2.resize( img, (0, 0), fx=zoom, fy=zoom)\n",
    "    img = img[int(round(cy - h/zoom * .5)) : int(round(cy + h/zoom * .5)),\n",
    "              int(round(cx - w/zoom * .5)) : int(round(cx + w/zoom * .5))]\n",
    "    return img\n",
    "\n",
    "# function that rotates an image by 90, 180, and 270 degrees and flips it horizontally and vertically and zooms in on the image and adjusts the brightness randomly\n",
    "def augment_image_zoom(img):\n",
    "    img_90 = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE) # rotate the image by 90 degrees clockwise\n",
    "    img_180 = cv2.rotate(img, cv2.ROTATE_180) # rotate the image by 180 degrees\n",
    "    img_270 = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE) # rotate the image by 270 degrees clockwise\n",
    "    img_fh = cv2.flip(img, 1) # flip the image horizontally\n",
    "    img_fv = cv2.flip(img, 0) # flip the image vertically\n",
    "    img_zoom = zoom_at(img, 1.2) # zoom in on the image\n",
    "    img_brt = cv2.convertScaleAbs(img, beta=0.8) # adjust the brightness randomly\n",
    "    return img, img_90, img_180, img_270, img_fh, img_fv, img_zoom, img_brt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a function that creates a copy of that image and adds it to the X_t_A array\n",
    "def add_image(X_t_A, y_t_A, img, label):\n",
    "    X_t_A = np.append(X_t_A, img)\n",
    "    y_t_A = np.append(y_t_A, label)\n",
    "    return X_t_A, y_t_A"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Apply Networks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.1 AlexNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session() # clear any previous models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_alex_model():\n",
    "    # Define your CNN model\n",
    "    model_alex = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(96, (11, 11), strides=(4, 4), padding='valid', activation='relu') # layer that convolves the input image with 96 different filters that are 11x11 pixels in size\n",
    "        keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid') # layer that downsamples the input representation by taking the maximum value over the window defined by pool_size for each dimension along the features axis\n",
    "        keras.layers.Conv2D(256, (5, 5), strides=(1, 1), padding='same', activation='relu') # layer that convolves the input image with 256 different filters that are 5x5 pixels in size\n",
    "        keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid') # layer that downsamples the input representation by taking the maximum value over the window defined by pool_size for each dimension along the features axis\n",
    "        keras.layers.Conv2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu') # layer that convolves the input image with 384 different filters that are 3x3 pixels in size\n",
    "        keras.layers.Conv2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu') # layer that convolves the input image with 384 different filters that are 3x3 pixels in size\n",
    "        keras.layers.Conv2D(384, (3, 3), strides=(1, 1), padding='same', activation='relu') # layer that convolves the input image with 384 different filters that are 3x3 pixels in size\n",
    "        keras.layers.Dense(4096, activation='relu') # layer with 4096 neurons that uses the ReLU activation function and is fully connected\n",
    "        keras.layers.Dropout(0.5), # layer that randomly sets input units to 0 with a 50% frequency at each step during training time, which helps prevent overfitting\n",
    "        keras.layers.Dense(4096, activation='relu') # layer with 4096 neurons that uses the ReLU activation function and is fully connected\n",
    "        keras.layers.Dropout(0.5), # layer that randomly sets input units to 0 with a 50% frequency at each step during training time, which helps prevent overfitting\n",
    "        keras.layers.Dense(8, activation='softmax') # layer with 8 neurons that uses the softmax activation function to output probabilities for each class\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random search + training of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn random serach function for a neural network\n",
    "param_grid = {\"optimizer\": [\"adam\", \"sgd\", \"rmsprop\"],\n",
    "                \"learning_rate\": [0.001, 0.01, 0.1],\n",
    "                \"momentum\": [0.0, 0.2, 0.4, 0.6, 0.8, 0.9],\n",
    "                \"epochs\": [10, 20, 30, 40, 50],\n",
    "                \"batch_size\": [10, 20, 30, 40, 50],\n",
    "                \"activation\": [\"relu\", \"sigmoid\", \"tanh\"],\n",
    "                \"dropout_rate\": [0.0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "                \"weight_constraint\": [1, 2, 3, 4, 5],\n",
    "                \n",
    "                \"neurons\": [1, 5, 10, 15, 20, 25, 30]}\n",
    "\n",
    "def random_search(X_train, y_train, X_test, y_test, param_grid, n_iter_search=10, n_jobs=-1, cv=3, verbose=1, random_state=1): \n",
    "    # create a random search object\n",
    "    random_search = RandomizedSearchCV(estimator=KerasClassifier(build_fn=create_alex_model, verbose=0), \n",
    "                                        param_distributions=param_grid,\n",
    "                                        n_iter=n_iter_search,\n",
    "                                        n_jobs=n_jobs,\n",
    "                                        cv=cv,\n",
    "                                        verbose=verbose,\n",
    "                                        random_state=random_state)\n",
    "    # fit the random search model\n",
    "    random_search.fit(X_train, y_train)\n",
    "    # print results\n",
    "    print(\"Best Score: \", random_search.best_score_)\n",
    "    print(\"Best Params: \", random_search.best_params_)\n",
    "    # evaluate the model on test data\n",
    "    print(\"Test Accuracy: \", random_search.score(X_test, y_test))\n",
    "    return random_search\n",
    "\n",
    "random_search(X_train, y_train, X_test, y_test, param_grid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [

    "# GoogLeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "from keras.metrics import CategoricalAccuracy\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, Dense, Dropout, Flatten, concatenate, AveragePooling2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_module(x, filters_1x1, filters_3x3_reduce, filters_3x3, filters_5x5_reduce, filters_5x5, filters_pool_proj):\n",
    "    path1 = Conv2D(filters_1x1, (1, 1), padding='same', activation='relu')(x)\n",
    "    path2 = Conv2D(filters_3x3_reduce, (1, 1), padding='same', activation='relu')(x)\n",
    "    path2 = Conv2D(filters_3x3, (3, 3), padding='same', activation='relu')(path2)\n",
    "    path3 = Conv2D(filters_5x5_reduce, (1, 1), padding='same', activation='relu')(x)\n",
    "    path3 = Conv2D(filters_5x5, (5, 5), padding='same', activation='relu')(path3)\n",
    "    path4 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    path4 = Conv2D(filters_pool_proj, (1, 1), padding='same', activation='relu')(path4)\n",
    "    return concatenate([path1, path2, path3, path4], axis=-1)\n",
    "\n",
    "def create_google_model():\n",
    "    input_layer = Input(shape=(227, 227, 3))\n",
    "\n",
    "    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', activation='relu')(input_layer)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = Conv2D(64, (1, 1), strides=(1, 1), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(192, (3, 3), strides=(1, 1), padding='same', activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = inception_module(x, 64, 96, 128, 16, 32, 32)\n",
    "    x = inception_module(x, 128, 128, 192, 32, 96, 64)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = inception_module(x, 192, 96, 208, 16, 48, 64)\n",
    "    x = inception_module(x, 160, 112, 224, 24, 64, 64)\n",
    "    x = inception_module(x, 128, 128, 256, 24, 64, 64)\n",
    "    x = inception_module(x, 112, 144, 288, 32, 64, 64)\n",
    "    x = inception_module(x, 256, 160, 320, 32, 128, 128)\n",
    "    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n",
    "    x = inception_module(x, 256, 160, 320, 32, 128, 128)\n",
    "    x = inception_module(x, 384, 192, 384, 48, 128, 128)\n",
    "\n",
    "    x = AveragePooling2D(pool_size=(7, 7), strides=(1, 1), padding='valid')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1000, activation='relu')(x)\n",
    "    output_layer = Dense(8, activation='softmax')(x)\n",
    "\n",
    "    # Define the model\n",
    "    model_googlenet = Model(input_layer, output_layer)\n",
    "\n",
    "    # Return the model\n",
    "    return model_googlenet"


   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},

   "source": [
    "ChatGPT for application "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your model\n",
    "model_google = create_model()\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "loss = CategoricalCrossentropy()\n",
    "metrics = [CategoricalAccuracy()]\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "# Fit the model to the training data\n",
    "log = model.fit(X_train, y_train, epochs=10, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "model.evaluate(X_test, y_test)\n",
    "\n",
    "# Use the model to make predictions\n",
    "predictions = model.predict(X_new)\n",
    "\n",
    "# If your task is multi-class classification, you can get the class with the highest probability\n",
    "import numpy as np\n",
    "class_predictions = np.argmax(predictions, axis=-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "random search + training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn random serach function for a neural network\n",
    "param_grid = {\"optimizer\": [\"adam\", \"sgd\", \"rmsprop\"],\n",
    "                \"learning_rate\": [0.001, 0.01, 0.1],\n",
    "                \"momentum\": [0.0, 0.2, 0.4, 0.6, 0.8, 0.9],\n",
    "                \"epochs\": [10, 20, 30, 40, 50],\n",
    "                \"batch_size\": [10, 20, 30, 40, 50],\n",
    "                \"activation\": [\"relu\", \"sigmoid\", \"tanh\"],\n",
    "                \"dropout_rate\": [0.0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "                \"weight_constraint\": [1, 2, 3, 4, 5],\n",
    "                \n",
    "                \"neurons\": [1, 5, 10, 15, 20, 25, 30]}\n",
    "\n",
    "def random_search(X_train, y_train, X_test, y_test, param_grid, n_iter_search=10, n_jobs=-1, cv=3, verbose=1, random_state=1): \n",
    "    # create a random search object\n",
    "    random_search = RandomizedSearchCV(estimator=KerasClassifier(build_fn=create_google_model, verbose=0), \n",
    "                                        param_distributions=param_grid,\n",
    "                                        n_iter=n_iter_search,\n",
    "                                        n_jobs=n_jobs,\n",
    "                                        cv=cv,\n",
    "                                        verbose=verbose,\n",
    "                                        random_state=random_state)\n",
    "    # fit the random search model\n",
    "    random_search.fit(X_train, y_train)\n",
    "    # print results\n",
    "    print(\"Best Score: \", random_search.best_score_)\n",
    "    print(\"Best Params: \", random_search.best_params_)\n",
    "    # evaluate the model on test data\n",
    "    print(\"Test Accuracy: \", random_search.score(X_test, y_test))\n",
    "    return random_search\n",
    "\n",
    "random_search(X_train, y_train, X_test, y_test, param_grid)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4019976191.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    kein Bock mehr\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "kein Bock mehr"
   ]

  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",

   "version": "3.10.10"

  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
